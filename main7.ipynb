{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3520a4d-2266-43b0-9203-7acb40d7323a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Text Analytics\\n1. Extract Sample document and apply following document\\npreprocessing methods: Tokenization, POS Tagging, stop\\nwords removal, Stemming and Lemmatization.\\n2. Create representation of document by calculating Term\\nFrequency and Inverse Document Frequency. '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Text Analytics\n",
    "1. Extract Sample document and apply following document\n",
    "preprocessing methods: Tokenization, POS Tagging, stop\n",
    "words removal, Stemming and Lemmatization.\n",
    "2. Create representation of document by calculating Term\n",
    "Frequency and Inverse Document Frequency. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "035a3ccf-d9dd-407c-9886-36fce353250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac73158b-90de-4d20-8722-9fe9dd942b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd37789f-c3eb-4cc8-8e33-eac5549f008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "document=\"Text analysis is deriving meaningful information from text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51eb5144-255e-4750-b709-23adc7112e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Text', 'analysis', 'is', 'deriving', 'meaningful', 'information', 'from', 'text']\n"
     ]
    }
   ],
   "source": [
    "tokens=word_tokenize(document)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68bb4753-0f97-4d1b-a382-ed415341f33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Text', 'JJ'), ('analysis', 'NN'), ('is', 'VBZ'), ('deriving', 'VBG'), ('meaningful', 'JJ'), ('information', 'NN'), ('from', 'IN'), ('text', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "postag=pos_tag(tokens)\n",
    "print(postag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0aaf3b5-b5fe-4fba-a1c1-b99d6538d5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Text', 'analysis', 'deriving', 'meaningful', 'information', 'text']\n"
     ]
    }
   ],
   "source": [
    "stopword=set(stopwords.words('English'))\n",
    "flitered_token=[word for word in tokens if word.lower() not in stopword]\n",
    "print(flitered_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f0c14cd-c74e-4340-93e5-46ae551900b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'analysi', 'deriv', 'meaning', 'inform', 'text']\n"
     ]
    }
   ],
   "source": [
    "stemmer=PorterStemmer()\n",
    "stemm=[stemmer.stem(word) for word in flitered_token ]\n",
    "print(stemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bd22a31-4c5b-4588-b03b-c6d4a45e2f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Text', 'analysis', 'deriving', 'meaningful', 'information', 'text']\n"
     ]
    }
   ],
   "source": [
    "lemm=WordNetLemmatizer()\n",
    "lemmaarr=[lemm.lemmatize(word) for word in flitered_token]\n",
    "# lemmatized = [lemm.lemmatize(word, tag) for word, tag in postag]\n",
    "print(lemmaarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc9f05be-639b-418d-a72f-90ec051d15cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[\n",
    "    \"Text analytics is a process of deriving meaningful information from text.\",\n",
    "    \"Natural Language Processing involves text analysis and machine learning.\",\n",
    "    \"Text mining is closely related to text analytics.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b347a491-6784-4457-8960-0e1bd817ab2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5)\t0.3419506234395804\n",
      "  (0, 6)\t0.3419506234395804\n",
      "  (0, 12)\t0.3419506234395804\n",
      "  (0, 4)\t0.3419506234395804\n",
      "  (0, 15)\t0.3419506234395804\n",
      "  (0, 16)\t0.3419506234395804\n",
      "  (0, 8)\t0.26006226305809793\n",
      "  (0, 1)\t0.26006226305809793\n",
      "  (0, 19)\t0.4039230934743582\n",
      "  (1, 10)\t0.3460885720028406\n",
      "  (1, 11)\t0.3460885720028406\n",
      "  (1, 2)\t0.3460885720028406\n",
      "  (1, 0)\t0.3460885720028406\n",
      "  (1, 7)\t0.3460885720028406\n",
      "  (1, 17)\t0.3460885720028406\n",
      "  (1, 9)\t0.3460885720028406\n",
      "  (1, 14)\t0.3460885720028406\n",
      "  (1, 19)\t0.20440548581747317\n",
      "  (2, 20)\t0.39066945883146126\n",
      "  (2, 18)\t0.39066945883146126\n",
      "  (2, 3)\t0.39066945883146126\n",
      "  (2, 13)\t0.39066945883146126\n",
      "  (2, 8)\t0.29711419312368575\n",
      "  (2, 1)\t0.29711419312368575\n",
      "  (2, 19)\t0.46147135147726714\n"
     ]
    }
   ],
   "source": [
    "vectorizer=TfidfVectorizer()\n",
    "\n",
    "x=vectorizer.fit_transform(corpus)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfe2a0a4-fe86-4498-96b7-495b6b3e2a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   analysis  analytics       and   closely  deriving      from  information  \\\n",
      "0  0.000000   0.260062  0.000000  0.000000  0.341951  0.341951     0.341951   \n",
      "1  0.346089   0.000000  0.346089  0.000000  0.000000  0.000000     0.000000   \n",
      "2  0.000000   0.297114  0.000000  0.390669  0.000000  0.000000     0.000000   \n",
      "\n",
      "   involves        is  language  ...   machine  meaningful    mining  \\\n",
      "0  0.000000  0.260062  0.000000  ...  0.000000    0.341951  0.000000   \n",
      "1  0.346089  0.000000  0.346089  ...  0.346089    0.000000  0.000000   \n",
      "2  0.000000  0.297114  0.000000  ...  0.000000    0.000000  0.390669   \n",
      "\n",
      "    natural        of   process  processing   related      text        to  \n",
      "0  0.000000  0.341951  0.341951    0.000000  0.000000  0.403923  0.000000  \n",
      "1  0.346089  0.000000  0.000000    0.346089  0.000000  0.204405  0.000000  \n",
      "2  0.000000  0.000000  0.000000    0.000000  0.390669  0.461471  0.390669  \n",
      "\n",
      "[3 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame(x.toarray(),columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ds_env)",
   "language": "python",
   "name": "ds_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
